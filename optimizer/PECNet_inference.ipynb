{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import yaml\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE074vugOlvW"
   },
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e9JbEpzcOjo6"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_size=(1024, 512), activation='relu', discrim=False, dropout=-1):\n",
    "        super(MLP, self).__init__()\n",
    "        dims = []\n",
    "        dims.append(input_dim)\n",
    "        dims.extend(hidden_size)\n",
    "        dims.append(output_dim)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(dims)-1):\n",
    "            self.layers.append(nn.Linear(dims[i], dims[i+1]))\n",
    "\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid() if discrim else None\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers)):\n",
    "            x = self.layers[i](x)\n",
    "            if i != len(self.layers)-1:\n",
    "                x = self.activation(x)\n",
    "                if self.dropout != -1:\n",
    "                    x = nn.Dropout(min(0.1, self.dropout/3) if i == 1 else self.dropout)(x)\n",
    "            elif self.sigmoid:\n",
    "                x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "N_1XDMj4Ot7r"
   },
   "outputs": [],
   "source": [
    "class PECNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 enc_past_size, \n",
    "                 enc_dest_size, \n",
    "                 enc_latent_size, \n",
    "                 dec_size, \n",
    "                 predictor_size, \n",
    "                 fdim, \n",
    "                 zdim, \n",
    "                 sigma,\n",
    "                 past_length, \n",
    "                 future_length, \n",
    "                 verbose):\n",
    "        '''\n",
    "        Args:\n",
    "            size parameters: Dimension sizes\n",
    "            sigma: Standard deviation used for sampling N(0, sigma)\n",
    "            past_length: Length of past history (number of timesteps)\n",
    "            future_length: Length of future trajectory to be predicted\n",
    "        '''\n",
    "        super(PECNet, self).__init__()\n",
    "\n",
    "        self.zdim = zdim\n",
    "        self.sigma = sigma\n",
    "\n",
    "        # takes in the past\n",
    "        self.encoder_past = MLP(input_dim = past_length*2, output_dim = fdim, hidden_size=enc_past_size)\n",
    "\n",
    "        self.encoder_dest = MLP(input_dim = 2, output_dim = fdim, hidden_size=enc_dest_size)\n",
    "\n",
    "        self.encoder_latent = MLP(input_dim = 2*fdim, output_dim = 2*zdim, hidden_size=enc_latent_size)\n",
    "\n",
    "        self.decoder = MLP(input_dim = fdim + zdim, output_dim = 2, hidden_size=dec_size)\n",
    "\n",
    "        self.predictor = MLP(input_dim = 2*fdim, output_dim = 2*(future_length-1), hidden_size=predictor_size)\n",
    "\n",
    "        architecture = lambda net: [l.in_features for l in net.layers] + [net.layers[-1].out_features]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Past Encoder architecture : {}\".format(architecture(self.encoder_past)))\n",
    "            print(\"Dest Encoder architecture : {}\".format(architecture(self.encoder_dest)))\n",
    "            print(\"Latent Encoder architecture : {}\".format(architecture(self.encoder_latent)))\n",
    "            print(\"Decoder architecture : {}\".format(architecture(self.decoder)))\n",
    "            print(\"Predictor architecture : {}\".format(architecture(self.predictor)))\n",
    "\n",
    "    def forward(self, x, dest = None, device=torch.device('cpu')):\n",
    "        # provide destination iff training\n",
    "        # assert model.training\n",
    "        assert self.training ^ (dest is None)\n",
    "\n",
    "        # encode\n",
    "        ftraj = self.encoder_past(x)\n",
    "\n",
    "        if not self.training:\n",
    "            z = torch.Tensor(x.size(0), self.zdim)\n",
    "            z.normal_(0, self.sigma)\n",
    "\n",
    "        else:\n",
    "            # during training, use the destination to produce generated_dest and use it again to predict final future points\n",
    "\n",
    "            # CVAE code\n",
    "            dest_features = self.encoder_dest(dest)\n",
    "            features = torch.cat((ftraj, dest_features), dim = 1)\n",
    "            latent =  self.encoder_latent(features)\n",
    "\n",
    "            mu = latent[:, 0:self.zdim] # 2-d array\n",
    "            logvar = latent[:, self.zdim:] # 2-d array\n",
    "\n",
    "            var = logvar.mul(0.5).exp_()\n",
    "            eps = torch.DoubleTensor(var.size()).normal_()\n",
    "            eps = eps.to(device)\n",
    "            z = eps.mul(var).add_(mu)\n",
    "\n",
    "        z = z.double().to(device)\n",
    "        decoder_input = torch.cat((ftraj, z), dim = 1)\n",
    "        generated_dest = self.decoder(decoder_input)\n",
    "\n",
    "        if self.training:\n",
    "            generated_dest_features = self.encoder_dest(generated_dest)\n",
    "\n",
    "            prediction_features = torch.cat((ftraj, generated_dest_features), dim = 1)\n",
    "\n",
    "            pred_future = self.predictor(prediction_features)\n",
    "            return generated_dest, mu, logvar, pred_future\n",
    "\n",
    "        return generated_dest\n",
    "\n",
    "    # separated for forward to let choose the best destination\n",
    "    # def predict(self, past, generated_dest, mask, initial_pos):\n",
    "    def predict(self, past, generated_dest):\n",
    "        ftraj = self.encoder_past(past)\n",
    "        generated_dest_features = self.encoder_dest(generated_dest)\n",
    "\n",
    "        prediction_features = torch.cat((ftraj, generated_dest_features), dim = 1)\n",
    "\n",
    "        interpolated_future = self.predictor(prediction_features)\n",
    "        return interpolated_future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_I_gQft7Pa7j"
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Vg0a_KB_PDoz"
   },
   "outputs": [],
   "source": [
    "def calculate_loss(x, reconstructed_x, mean, log_var, criterion, future, interpolated_future):\n",
    "    # Weights\n",
    "    w1 = torch.tensor([10, 1]).to(device)\n",
    "    w2 = torch.tensor([10, 1] * 11).to(device)\n",
    "    \n",
    "    # reconstruction loss\n",
    "    # RCL_dest = criterion(x, reconstructed_x)\n",
    "    RCL_dest = torch.mean(w1 * (x - reconstructed_x) ** 2)\n",
    "    \n",
    "    # ADL_traj = criterion(future, interpolated_future) # better with l2 loss\n",
    "    ADL_traj = torch.mean(w2 * (future - interpolated_future) ** 2)\n",
    "    \n",
    "    # kl divergence loss\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "    return RCL_dest, KLD, ADL_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZU3HNOdDSsYB"
   },
   "outputs": [],
   "source": [
    "def load_hyper_parameters(file_name='optimal.yaml'):\n",
    "    with open(file_name, 'r') as file:\n",
    "        hyper_params = yaml.load(file)\n",
    "    \n",
    "    return hyper_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bpl-Tpo1YBAU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shashanks./opt/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/ipykernel_launcher.py:3: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "hyper_params = load_hyper_parameters()\n",
    "hyper_params[\"data_scale\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./trained.pt', map_location=device)\n",
    "hyper_params = checkpoint[\"hyper_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past Encoder architecture : [16, 512, 256, 16]\n",
      "Dest Encoder architecture : [2, 8, 16, 16]\n",
      "Latent Encoder architecture : [32, 8, 50, 32]\n",
      "Decoder architecture : [32, 1024, 512, 1024, 2]\n",
      "Predictor architecture : [32, 1024, 512, 256, 22]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PECNet(\n",
    "    hyper_params[\"enc_past_size\"],\n",
    "    hyper_params[\"enc_dest_size\"],\n",
    "    hyper_params[\"enc_latent_size\"],\n",
    "    hyper_params[\"dec_size\"],\n",
    "    hyper_params[\"predictor_hidden_size\"],\n",
    "    hyper_params[\"fdim\"], \n",
    "    hyper_params[\"zdim\"], \n",
    "    hyper_params[\"sigma\"], \n",
    "    hyper_params[\"past_length\"], \n",
    "    hyper_params[\"future_length\"], \n",
    "    verbose=True\n",
    ")\n",
    "model = model.double().to(device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_of_n = 20\n",
    "model.eval()\n",
    "scenes_data = np.load('../../../code/scene_data.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test time error in destination best: 1.415 and mean: 20.876\n",
      "Test time error overall (ADE) best: 2.035\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 1.813 and mean: 17.633\n",
      "Test time error overall (ADE) best: 2.368\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 5.520 and mean: 26.111\n",
      "Test time error overall (ADE) best: 2.739\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 1.937 and mean: 21.952\n",
      "Test time error overall (ADE) best: 2.285\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 4.876 and mean: 26.626\n",
      "Test time error overall (ADE) best: 2.576\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.561 and mean: 27.291\n",
      "Test time error overall (ADE) best: 2.257\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 1.615 and mean: 24.655\n",
      "Test time error overall (ADE) best: 1.673\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.554 and mean: 19.375\n",
      "Test time error overall (ADE) best: 2.247\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.513 and mean: 22.162\n",
      "Test time error overall (ADE) best: 2.270\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 1.496 and mean: 19.443\n",
      "Test time error overall (ADE) best: 1.608\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.517 and mean: 18.408\n",
      "Test time error overall (ADE) best: 1.959\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.783 and mean: 21.063\n",
      "Test time error overall (ADE) best: 2.528\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 1.358 and mean: 21.609\n",
      "Test time error overall (ADE) best: 1.507\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 5.481 and mean: 27.481\n",
      "Test time error overall (ADE) best: 3.870\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.244 and mean: 21.860\n",
      "Test time error overall (ADE) best: 2.295\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.046 and mean: 21.881\n",
      "Test time error overall (ADE) best: 2.008\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.298 and mean: 20.131\n",
      "Test time error overall (ADE) best: 2.008\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 1.553 and mean: 20.964\n",
      "Test time error overall (ADE) best: 2.290\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.497 and mean: 26.483\n",
      "Test time error overall (ADE) best: 2.519\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.463 and mean: 20.175\n",
      "Test time error overall (ADE) best: 1.966\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.449 and mean: 20.189\n",
      "Test time error overall (ADE) best: 2.364\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.238 and mean: 22.323\n",
      "Test time error overall (ADE) best: 2.285\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.177 and mean: 23.222\n",
      "Test time error overall (ADE) best: 2.431\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.539 and mean: 25.153\n",
      "Test time error overall (ADE) best: 2.529\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.549 and mean: 22.115\n",
      "Test time error overall (ADE) best: 2.389\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 4.307 and mean: 23.465\n",
      "Test time error overall (ADE) best: 2.431\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.624 and mean: 23.197\n",
      "Test time error overall (ADE) best: 2.546\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.488 and mean: 21.670\n",
      "Test time error overall (ADE) best: 2.926\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 8.014 and mean: 30.808\n",
      "Test time error overall (ADE) best: 4.277\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.421 and mean: 23.494\n",
      "Test time error overall (ADE) best: 2.726\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.265 and mean: 20.247\n",
      "Test time error overall (ADE) best: 2.634\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.776 and mean: 22.001\n",
      "Test time error overall (ADE) best: 1.749\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.427 and mean: 22.003\n",
      "Test time error overall (ADE) best: 2.830\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 5.454 and mean: 29.045\n",
      "Test time error overall (ADE) best: 3.765\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.938 and mean: 23.005\n",
      "Test time error overall (ADE) best: 2.393\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.586 and mean: 22.828\n",
      "Test time error overall (ADE) best: 2.977\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.763 and mean: 23.783\n",
      "Test time error overall (ADE) best: 2.379\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.474 and mean: 23.834\n",
      "Test time error overall (ADE) best: 2.389\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 5.432 and mean: 23.603\n",
      "Test time error overall (ADE) best: 3.258\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.207 and mean: 22.807\n",
      "Test time error overall (ADE) best: 1.479\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.646 and mean: 20.909\n",
      "Test time error overall (ADE) best: 2.797\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 8.374 and mean: 28.341\n",
      "Test time error overall (ADE) best: 4.733\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 2.333 and mean: 20.315\n",
      "Test time error overall (ADE) best: 2.379\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 3.090 and mean: 22.924\n",
      "Test time error overall (ADE) best: 2.235\n",
      "--------------------------------------------------\n",
      "Test time error in destination best: 1.730 and mean: 20.672\n",
      "Test time error overall (ADE) best: 2.126\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "optimizer_data = []\n",
    "with torch.no_grad():\n",
    "    for scene in scenes_data:\n",
    "        trajx = torch.tensor(np.array(scene), requires_grad=False)\n",
    "        traj = trajx - trajx[:, :1, :]\n",
    "        traj *= hyper_params[\"data_scale\"]\n",
    "\n",
    "        traj = torch.DoubleTensor(traj).to(device)\n",
    "        x = traj[:, :hyper_params['past_length'], :]\n",
    "        y = traj[:, hyper_params['past_length']:, :]\n",
    "        y = y.cpu().numpy()\n",
    "\n",
    "        # reshape the data\n",
    "        x = x.view(-1, x.shape[1]*x.shape[2])\n",
    "        x = x.to(device)\n",
    "\n",
    "        dest = y[:, -1, :]\n",
    "        all_l2_errors_dest = []\n",
    "        all_guesses = []\n",
    "        for _ in range(best_of_n):\n",
    "            # dest_recon = model.forward(x, initial_pos, device=device)\n",
    "            dest_recon = model.forward(x, device=device)\n",
    "            dest_recon = dest_recon.cpu().numpy()\n",
    "            all_guesses.append(dest_recon)\n",
    "\n",
    "            l2error_sample = np.linalg.norm(dest_recon - dest, axis = 1)\n",
    "            all_l2_errors_dest.append(l2error_sample)\n",
    "\n",
    "        all_l2_errors_dest = np.array(all_l2_errors_dest)\n",
    "        all_guesses = np.array(all_guesses)\n",
    "        \n",
    "        inp = np.array(scene)\n",
    "        optimizer_data.append([inp, all_guesses])\n",
    "        # average error\n",
    "        l2error_avg_dest = np.mean(all_l2_errors_dest)\n",
    "\n",
    "        # choosing the best guess\n",
    "        indices = np.argmin(all_l2_errors_dest, axis = 0)\n",
    "\n",
    "        best_guess_dest = all_guesses[indices,np.arange(x.shape[0]),  :]\n",
    "\n",
    "        # taking the minimum error out of all guess\n",
    "        l2error_dest = np.mean(np.min(all_l2_errors_dest, axis = 0))\n",
    "\n",
    "        best_guess_dest = torch.DoubleTensor(best_guess_dest).to(device)\n",
    "\n",
    "        interpolated_future = model.predict(x, best_guess_dest)\n",
    "        # interpolated_future = interpolated_future.cpu().numpy()\n",
    "        interpolated_future = interpolated_future.cpu().numpy()\n",
    "        best_guess_dest = best_guess_dest.cpu().numpy()\n",
    "\n",
    "         # final overall prediction\n",
    "        predicted_future = np.concatenate((interpolated_future, best_guess_dest), axis = 1)\n",
    "        predicted_future = np.reshape(predicted_future, (-1, hyper_params['future_length'], 2)) # making sure\n",
    "        # ADE error\n",
    "        l2error_overall = np.mean(np.linalg.norm(y - predicted_future, axis = 2))\n",
    "\n",
    "        l2error_overall /= hyper_params[\"data_scale\"]\n",
    "        l2error_dest /= hyper_params[\"data_scale\"]\n",
    "        l2error_avg_dest /= hyper_params[\"data_scale\"]\n",
    "\n",
    "        print('Test time error in destination best: {:0.3f} and mean: {:0.3f}'.format(l2error_dest, l2error_avg_dest))\n",
    "        print('Test time error overall (ADE) best: {:0.3f}'.format(l2error_overall))\n",
    "        print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('optimizer_data.npy', optimizer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene in optimizer_data:\n",
    "    trajectories = scene[0] # num_vehicles x 20 x 2\n",
    "    goal_predictions = scene[1] # num_goals x num_vehicles x 2 (here num_goals is 20)\n",
    "    # To get the bounding boxes for each vehicle, simply find the min_x, min_y, max_x, max_y for each vehicle in the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 20, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectories.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 11, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
